# 2장. DeepSeek-R1으로 시작하는 기초 RAG 정복

본 장에서는 복잡한 시스템 구축에 앞서, RAG(Retrieval-Augmented Generation)의 핵심 원리를 단계별 실습을 통해 학습합니다. LLM이 모르는 지식에 대해 어떻게 답변을 실패하고, 이를 RAG가 어떻게 보완하는지 코드로 직접 확인합니다.

---

## 1. 사전 준비 및 핵심 기술 이해

이 책의 모든 실습 코드는 GitHub 저장소에 공개되어 있습니다. 실습을 시작하기 전, 아래 명령어로 전체 프로젝트 코드를 클론(Clone)하십시오.

```bash
git clone https://github.com/nomadlab/ai-llm-rag-study.git
cd ai-llm-rag-study
```

> **참고**: 2장의 실습 코드는 `01_basic_rag` 폴더에 위치합니다.

### 1.1 파이썬(Python) 설치 확인

실습을 위해서는 **Python 3.10 이상** 버전이 필요합니다. 터미널(또는 명령 프롬프트)에서 아래 명령어로 설치 여부를 확인하십시오.

```bash
python --version
# 또는
python3 --version
```

설치되어 있지 않다면 공식 홈페이지(python.org)에서 다운로드하여 설치합니다.
**Windows 사용자**는 설치 화면 하단의 **"Add Python to PATH"** 옵션을 반드시 체크해야 터미널에서 명령어가 인식됩니다.

### 1.2 필수 라이브러리 설치

파이썬이 준비되었다면, 다음 명령어로 RAG 실습에 필요한 4대장 라이브러리를 설치합니다.

```bash
pip install langchain langchain-community langchain-ollama langchain-chroma
```

#### macOS (맥) 사용자

`pip` 대신 `python3 -m pip`를 사용하여 현재 실행 중인 파이썬에 확실하게 설치합니다.

```bash
python3 -m pip install langchain langchain-community langchain-chroma langchain-ollama
```

#### Windows (윈도우) 사용자

`py` 명령어를 사용하여 파이썬 런처가 올바른 버전을 찾도록 합니다.

```bash
py -m pip install langchain langchain-community langchain-chroma langchain-ollama
```

---

### 1.3 Ollama 모델 설치 (공통)

실습을 위해서는 AI의 두뇌 역할을 하는 **생성 모델**과, 언어를 숫자로 변환하는 **임베딩 모델**이 모두 필요합니다.

먼저, 로컬 LLM 실행 도구인 **Ollama**를 설치해야 합니다.

- **다운로드**: [ollama.com](https://ollama.com) 접속 후 OS에 맞는 버전을 설치합니다.

설치가 완료되면 터미널(또는 명령 프롬프트)을 열고, 아래 명령어를 한 줄씩 실행하여 모델을 다운로드합니다.

> **주의**: Ollama 프로그램이 실행 중이어야 합니다.

1.  **추론 모델 (DeepSeek-R1)**: 논리적 사고를 담당합니다.

    ```bash
    ollama pull deepseek-r1:8b
    ```

2.  **임베딩 모델 (Nomic Embed Text)**: 텍스트를 벡터로 변환합니다.
    ```bash
    ollama pull nomic-embed-text
    ```

---

### 1.4 RAG 핵심 용어 이해

- **임베딩(Embedding)**: 인간의 언어를 컴퓨터가 이해할 수 있는 **숫자(벡터)의 나열**로 바꾸는 과정입니다. "사과"와 "배"는 숫자가 비슷하고, "자동차"와는 거리가 멉니다.
- **벡터DB(VectorDB)**: 임베딩된 숫자들을 저장하고, 질문과 가장 숫자가 비슷한(거리가 가까운) 문서를 찾아주는 데이터베이스입니다.
- **청킹(Chunking)**: 긴 문서를 한 번에 처리할 수 없으므로, **의미 단위로 잘게 쪼개는** 작업입니다.

---

## 2. [실습 1] LLM 단독 질의의 한계 (step1_fail.py)

### 학습 목표

1. LLM이 학습하지 않은 비공개 정보(사내 규정)에 대해 어떻게 답변하는지 확인합니다.
2. **할루시네이션(Hallucination)** 현상을 직접 목격하고 그 위험성을 이해합니다.

가장 먼저, 모델이 학습했을 리 없는 가상의 회사 규정("테크컴퍼니 신입사원 연차 규정")을 질문해 봅니다.

### 0단계: 실습 폴더로 이동

GitHub에서 코드를 클론했다면 `01_basic_rag` 폴더로 이동합니다.

### 1단계: 실습 파일 확인

`step1_fail.py` 파일을 확인합니다.

```python
from langchain_ollama import ChatOllama

# 로컬 LLM 연결
llm = ChatOllama(model="deepseek-r1:8b", temperature=0)

# 질문: 모델이 학습했을 리 없는 가상의 회사 규정
question = "우리 회사(테크컴퍼니)의 신입사원 연차 발생 규정이 어떻게 돼?"

print(f"질문: {question}\n")
response = llm.invoke(question)
print(f"답변:\n{response.content}")
```

### 2단계: 코드 실행

```bash
python step1_fail.py
```

- **결과**: 모델은 일반적인 근로기준법을 말하거나 모른다고 답변합니다. (지식의 부재)

```text
질문: 우리 회사(테크컴퍼니)의 신입사원 연차 발생 규정이 어떻게 돼?

답변:
죄송하지만 저는 해당 회사의 내부 규정을 알 수 없습니다.
보편적인 근로기준법에 따르면 1년간 80% 이상 출근 시 15일의 연차가 발생하지만,
정확한 내용은 귀사의 사규나 인사팀에 문의하시기 바랍니다.
```

### 결과 분석: 왜 실패했나요?

1.  **지식의 부재**: DeepSeek-R1은 인터넷에 공개된 데이터만 학습했습니다. **'테크컴퍼니'**라는 가상 회사의 내부 규정은 알 수 없습니다.
2.  **그럴싸한 거짓말 (Hallucination)**: 모델은 종종 자신이 아는 **일반적인 근로기준법**을 마치 정답인 것처럼 이야기하는 실수를 범합니다.
3.  **결론**: 외부 지식(우리 회사 데이터)이 없는 LLM은 내부 업무에 활용하기 어렵습니다. "정보를 줘야 답을 한다"는 원칙을 확인했습니다.

---

## 3. [실습 2] RAG의 첫 걸음: 컨텍스트 직접 주입

### 학습 목표

1. LLM에게 참고할 정보를 직접 전달하여 답변의 정확도를 높이는 방법을 익힙니다.
2. AI를 근거에 묶어두는 **그라운딩(Grounding)**의 개념을 이해합니다.

문서가 짧을 경우, 질문 앞에 규정을 복사해서 전달할 수 있습니다. 이를 **컨텍스트 주입(Context Injection)**이라 합니다.

### 1단계: 실습 파일 확인

`step2_context.py` 파일을 확인합니다.

```python
from langchain_ollama import ChatOllama

llm = ChatOllama(model="deepseek-r1:8b", temperature=0)

# 1. 정보를 변수에 담습니다
context_data = """
[테크컴퍼니 취업규칙]
1. 신입사원은 입사 후 3년 동안은 연차가 없다.
2. 대신 매월 1회 '리프레시 데이'를 유급으로 제공한다.
"""

# 2. 프롬프트에 정보를 포함시킵니다.
question = "우리 회사(테크컴퍼니)의 신입사원 연차 발생 규정이 어떻게 돼?"
prompt = f"""
아래 [참고 정보]를 보고 질문에 답해줘.
[참고 정보]
{context_data}

질문: {question}
"""

response = llm.invoke(prompt)
print(f"답변:\n{response.content}")
```

### 2단계: 코드 실행

```bash
python step2_context.py
```

- **결과**: AI가 정확하게 답변합니다. 하지만 문서가 수만 페이지라면 이 방식은 불가능합니다.

```text
답변:
[테크컴퍼니 취업규칙]에 따르면, 신입사원은 입사 후 3년 동안은 연차가 발생하지 않습니다.
대신 매월 1회 유급으로 제공되는 '리프레시 데이'를 사용할 수 있습니다.
```

### 결과 분석: 반쪽짜리 성공인 이유

1.  **정확도 향상**: 외부 데이터(`context_data`)를 주었으므로 AI가 정확하게 답변합니다. 이를 **그라운딩(Grounding)**이라 합니다.
2.  **치명적인 한계**:
    - **입력 길이 제한**: 문서가 수천 페이지라면 프롬프트에 다 넣을 수 없습니다. (Context Window 초과)
    - **비용 문제**: 입력하는 글자 수가 많을수록 처리 시간이 늘어나고 비용이 발생합니다.
3.  **결론**: 이 방법은 문서가 매우 짧을 때만 유효하며, 방대한 데이터를 처리하기 위해서는 **3단계(VectorDB & RAG)**가 필요합니다.

---

## 4. [실습 3] VectorDB와 시맨틱 검색

### 학습 목표

1. 수만 개의 정보 중 필요한 것만 골라내는 **RAG 아키텍처**를 이해합니다.
2. 데이터를 잘라 저장하는 **청킹(Chunking)**의 중요성을 배웁니다.

데이터가 많을 때를 대비해, 정보를 조각내어 저장하고 필요한 부분만 검색하는 방식이 필요합니다.

### 4.1 RAG 프로세스 다이어그램

```mermaid
graph LR
    User[사용자 질문] --> Search[1. 검색: VectorDB]
    Search --> Prompt[2. 컨텍스트: 프롬프트 구성]
    Prompt --> LLM[3. 생성: DeepSeek-R1]
    LLM --> Answer[최종 답변]
```

### 1단계: 실습 파일 확인

`step3_rag.py` 파일을 확인합니다.

```python
from langchain_classic.chains import RetrievalQA
from langchain_chroma import Chroma
from langchain_ollama import OllamaEmbeddings, ChatOllama
from langchain_core.documents import Document
from langchain_core.prompts import PromptTemplate

# 1. 데이터 준비 (청킹)
docs = [
    Document(page_content="[인사규정] 신입사원은 처음 3년 동안 연차가 없습니다. 대신 매월 1회 '리프레시 데이'를 사용합니다.", metadata={"source": "인사"}),
    Document(page_content="[보안규정] 승인된 보안 USB만 사용해야 합니다.", metadata={"source": "보안"}),
]

# 2. VectorDB 생성 (임베딩)
embeddings = OllamaEmbeddings(model="nomic-embed-text")
vectorstore = Chroma.from_documents(documents=docs, embedding=embeddings)

# 3. 검색기 및 프롬프트 설정
retriever = vectorstore.as_retriever(search_kwargs={"k": 1})
template = """참고 정보를 바탕으로 질문에 답하세요. 정보가 없다면 모른다고 답하세요.
참고 정보: {context}
질문: {question}
답변:"""
PROMPT = PromptTemplate(template=template, input_variables=["context", "question"])

# 4. 실행
llm = ChatOllama(model="deepseek-r1:8b", temperature=0)
qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, chain_type_kwargs={"prompt": PROMPT})

question = "신입사원 휴가 규정 알려줘."
result = qa_chain.invoke({"query": question})
print(f"답변:\n{result['result']}")
```

### 2단계: 코드 실행

```bash
python step3_rag.py
```

```text
답변:
신입사원은 입사 후 처음 3년 동안은 연차가 없습니다.
대신 매월 1회 '리프레시 데이'를 사용합니다.
```

### 결과 분석: 청킹(Chunking)의 마법

1.  **동작 특징**: AI가 질문을 받으면 전체 문서 중 가장 관련 있는 문단([인사규정])만 쏙 뽑아서 읽습니다.
2.  **효율성**: 수만 페이지의 문서가 있어도 필요한 부분만 검색(Search)하여 읽기 때문에 속도가 빠르고 정확도가 높습니다.
3.  **결론**: VectorDB는 **"AI를 위한 전용 도서관 사서"** 역할을 합니다. 방대한 자료 속에서 정답이 있는 페이지만 찾아줍니다.

---

## 5. [실습 4] DeepSeek-R1의 추론(Reasoning) 활용

RAG의 진가는 단순 검색을 넘어 LLM이 찾은 정보를 바탕으로 논리적인 사고를 할 때 나타납니다.

### 1단계: 실습 파일 확인

`step4_rag.py` 파일을 확인합니다.

**질문**: "입사 6개월 차인데 리프레시 데이 2번 썼어. 몇 번 남았는지 계산해줘."

**AI의 사고 과정**:

1. **규정 검색**: VectorDB에서 "매월 1회 발생"이라는 핵심 규정을 찾아냅니다.
2. **논리 연산**: "입사 6개월 = 총 6회 발생"이라는 사실을 도출하고, "6회 - 2회 사용 = 4회 남음"을 계산합니다.
3. **답변 생성**: 계산된 결과를 바탕으로 최종 답변을 구성합니다.

### 2단계: 코드 실행

```bash
python step4_rag.py
```

```text
질문: 입사 6개월 차인데 리프레시 데이 2번 썼어. 몇 번 남았는지 계산해줘.

--- AI 답변 ---
입사 6개월 차라면 총 6회의 리프레시 데이가 발생했습니다.
그중 2회를 사용했으므로, 남은 리프레시 데이는 **6 - 2 = 4회**입니다.

(근거: [인사규정] 신입사원은... 매월 1회 '리프레시 데이'를 사용합니다.)
```

### 결과 분석: 왜 '추론 모델'인가요?

실험에 사용된 **DeepSeek-R1**과 같은 모델은 단순 요약을 넘어 다음과 같은 사고 과정을 거칩니다.

1.  **생각의 사슬 (Chain of Thought)**: 답을 내놓기 전, 스스로 문제를 단계별로 쪼갭니다. (6개월 발생 -> 2개 사용 -> 뺄셈)
2.  **복합 문맥 이해**: 문서에 없는 '사용자의 현재 상황(6개월차)'을 문서의 '일반 규칙(매월 1회)'에 대입하여 계산합니다.
3.  **결론**: 진정한 사내 AI 비서는 단순히 정보를 찾아주는 것을 넘어, **찾은 정보를 바탕으로 업무를 대신 처리(계산, 판단)**해 줄 수 있어야 합니다.

---

## 6. 요약: RAG의 3대 요소

| 요소          | 기술        | 역할                                      |
| :------------ | :---------- | :---------------------------------------- |
| **Search**    | VectorDB    | 방대한 데이터 중 관련 정보 찾기           |
| **Context**   | Prompt      | 찾은 정보를 AI에게 전달                   |
| **Reasoning** | DeepSeek-R1 | 전달받은 정보를 바탕으로 논리적 답변 생성 |

이제 기초를 다졌습니다. 다음 장(3장)부터는 실제 사내 시스템과 연동하기 위한 인프라 구축을 시작하겠습니다.
