# 2단계: [반쪽 성공] 프롬프트에 텍스트 주입 (Context Injection)

### ◈ 학습 목표
1. LLM에게 참고할 정보를 직접 전달하여 답변의 정확도를 높이는 방법을 익힙니다.
2. AI를 근거에 묶어두는 **그라운딩(Grounding)**의 개념을 이해합니다.
3. 이 방식이 가진 물리적 한계(입력 길이 제한)를 체감합니다.

---

LLM에게 정보를 강제로 주입하면 어떻게 되는지 봅니다. 문서가 짧을 때는 가장 확실하고 쉬운 방법입니다.

---

## 1) 코드: `step2_context.py`

```python
from langchain_ollama import ChatOllama

llm = ChatOllama(model="deepseek-r1:8b", temperature=0)

# 1. 정보를 변수에 담습니다 (아직 DB 안 씀)
context_data = """
[테크컴퍼니 취업규칙]
1. 신입사원은 입사 후 3년 동안은 연차가 없다. (파격적인 규정)
2. 대신 매월 1회 '리프레시 데이'를 유급으로 제공한다.
3. 3년 근속 시 30일의 연차가 일시에 발생한다.
"""

question = "우리 회사(테크컴퍼니)의 신입사원 연차 발생 규정이 어떻게 돼?"

# 2. 프롬프트에 정보를 포함시킵니다.
prompt = f"""
아래 [참고 정보]를 보고 질문에 답해줘.
[참고 정보]
{context_data}

질문: {question}
"""
print(f"질문: {question}\n")
response = llm.invoke(prompt)
print(f"답변:\n{response.content}")
```

---

## 2) 실제 실행 결과
```text
질문: 우리 회사(테크컴퍼니)의 신입사원 연차 발생 규정이 어떻게 돼?

답변:
[테크컴퍼니 취업규칙]에 따르면, **신입사원의 연차 발생 규정**은 다음과 같습니다:

1. **신입사원은 입사 후 3년 동안 연차가 없다.**  
   - 즉, 첫 3년간 쌓이는 연차는 없습니다.

2. **대신 매월 1회 '리프레시 데이'를 유급으로 제공한다.**  
   - 매월 1일 제공되는 유급 휴무로, 연차 대신 사용됩니다.

3. **3년 근속 시 30일의 연차가 일시에 발생한다.**  
   - 3년 차 이후부터 30일의 연차가 일시에 부여됩니다.

이러한 규정은 **신입사원에게 연차가 부족하지만, 대체 휴무와 3년 만에 일시적 연차**를 제공하는 파격적인 정책입니다.
```

---

## 3) 핵심 개념: 그라운딩 (Grounding)
이번 단계에서 AI가 거짓말을 하지 않고 정확히 답변한 이유입니다.

- **정의**: AI가 자신의 학습된 기억(불확실함)에 의존하지 않고, **제공된 증거(Context)**에 기반하여 답변하도록 묶어두는 기술입니다.
- **예시 상황**:
  - **Grounding 실패**: "상상해서 말해봐" -> (AI: 막 지어냄)
  - **Grounding 성공**: "이 뉴스 기사만 보고 답해" -> (AI: 기사 내용만 말함)
- **효과**: 할루시네이션(거짓 답변)을 획기적으로 줄여줍니다.

---

## 4) 실행 결과 분석

1. **정확도 향상**: 외부 데이터(`context_data`)를 주었으므로 AI가 정확하게 답변합니다. (Grounding 성공)
2. **치명적인 한계**:
    - **입력 길이 제한**: 문서가 수천 페이지라면 프롬프트에 다 넣을 수 없습니다. (Context Window 초과)
    - **비용 문제**: 입력하는 글자 수가 많을수록 API 비용이나 처리 시간이 늘어납니다.

**✓ 결론**: 이 방법은 문서가 매우 짧을 때만 유효하며, 방대한 데이터를 처리하기 위해서는 **3단계(VectorDB & RAG)**가 필요합니다.

---

### ↳ Next Step
"문서가 1,000페이지라면 어떡하지?"
모든 문서를 다 읽게 하는 대신, 필요한 부분만 광속으로 찾아내는 **3단계: VectorDB와 RAG**의 세계로 들어갑니다.
