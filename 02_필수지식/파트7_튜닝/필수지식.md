# PART 7. RAG 튜닝: "되는 수준"에서 "쓸만한 수준"으로

## 1. 탄생 배경 (Background)
- **초기 환멸 단계**: RAG 프로토타입을 만들면 처음엔 신기하지만, 조금만 복잡한 질문을 던지면 엉뚱한 문서를 가져오거나(거짓 양성), 정작 필요한 문서를 못 찾음(거짓 음성).
- **품질의 벽**: "그냥 검색"이 아니라 **"정확한 검색"**을 위해 검색 파이프라인의 각 단계를 최적화해야 함.

## 2. 개념 (Concept)
- **ReRanker (재순위화)**: 1차로 빠르게 검색한 50개 문서(Vector Search)를, 느리지만 똑똑한 모델(Cross-Encoder)로 정밀하게 다시 채점하여 순서를 바꾸는 기술.
- **Hybrid Search (하이브리드 검색)**: 의미 기반(Vector) 검색과 키워드 기반(BM25) 검색을 섞어서 사용하는/앙상블하는 기법.
- **Parent Document Retriever**: 검색은 '작은 조각'으로 하되, LLM에게는 그 조각이 포함된 '큰 문맥(부모 문서)'을 던져주는 전략.

## 3. 역할 (Role)
- **정밀 타격**: 사용자의 모호한 질문 속에서도 "진짜 의도"에 맞는 문서를 찾아냄.
- **문맥 보강**: 잘린 문장(Chunk)만으로는 부족한 앞뒤 맥락을 보완하여 LLM에게 전달.

## 4. 도입 이유 (Reason)
- **Vector의 한계**: "2024년 HR 규정"이라고 검색했을 때, Vector는 "2020년 HR 규정"도 내용이 비슷하므로 가져옴(최신성 무시). 이를 필터링해야 함.
- **고유명사 인식**: 사람 이름이나 제품명은 의미(Vector)보다 정확한 철자(Keyword) 매칭이 중요함.

## 5. 장단점 (Pros & Cons)
| 구분 | 내용 |
| :--- | :--- |
| **장점** | - **사용자 경험(UX) 급상승**: "AI가 내 말을 찰떡같이 알아듣네"라는 느낌을 줌.<br>- **신뢰도**: 답변의 근거가 정확해지므로 할루시네이션이 자연스럽게 줄어듦. |
| **단점** | - **속도 저하**: ReRanking이나 Hybrid Search는 연산량이 많아 응답 속도가 느려짐.<br>- **복잡성**: 파이프라인이 길어지고 튜닝할 파라미터(Weight, k값)가 많아짐. |

## 6. 차별점 (Differences)
- **vs Basic RAG**:
  - Basic: 질문 -> VectorDB -> LLM (단순)
  - Advanced: 질문 -> Query변환 -> Hybrid검색 -> ReRanking -> LLM (정교)

## 7. 관련 기술 (Related Tech)
- **BGE-Reranker**: 오픈소스로 사용 가능한 고성능 ReRanking 모델.
- **BM25**: 전통적인 검색 엔진(Elasticsearch, Solr)에서 쓰는 키워드 스코어링 알고리즘.
- **Self-Query Retriever**: LLM이 질문을 분석해 메타데이터 필터(Filter)를 자동으로 생성하는 기술.
