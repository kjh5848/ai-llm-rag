# 집필 가이드: 파트 0. 이 책의 목표와 핵심 아키텍처

이 문서는 작가님이 **파트 0**을 집필하실 때 논리적 일관성을 유지하고, 독자에게 전문적인 통찰을 전달할 수 있도록 돕는 상세 레퍼런스입니다.

---

## 1. 핵심 메시지 (Core Message)
> **"우리는 AI에게 새로운 지식을 무작정 외우게(Fine-tuning) 하는 대신, 똑똑하게 서류를 찾아보고(RAG) 도구를 다루는(MCP) 법을 가르칠 것이다."**

이 파트의 목적은 독자가 이 책을 끝냈을 때 완성하게 될 **'지능형 사내 비서'**의 모습을 구체적으로 상상하게 만들고, 왜 RAG와 MCP의 조합이 현시대 비즈니스 AI의 정답인지 설득하는 것입니다.

---

## 2. 집필 논리 흐름 (Writing Logic Flow)

1.  **도입: LLM의 화려함 뒤에 숨겨진 차가운 현실**
    *   ChatGPT는 똑똑하지만, "우리 팀 김 대리 이번 달 연차 며칠 남았어?"라는 질문에는 바보가 된다는 점을 지적하며 독자의 공감을 유도합니다.
2.  **문제 진단: 왜 LLM은 사내 데이터를 모를까?**
    *   학습 컷오프(Knowledge Cut-off)와 폐쇄 데이터의 특성을 설명합니다.
3.  **대안 제시: Fine-tuning vs RAG (책의 핵심 논리)**
    *   파인튜닝이 "시험 범위를 통째로 암기"하는 것이라면, RAG는 "오픈북 테스트"임을 비유로 설명합니다. 
    *   사내 데이터는 매일 바뀌기 때문에 실시간으로 책을 찾아보는 RAG가 훨씬 유리함을 강조합니다.
4.  **확장: 검색을 넘어 행동으로 (MCP의 등장)**
    *   문서만 찾아서는 부족합니다. 실제 DB(숫자)를 조회할 수 있는 MCP(Model Context Protocol)를 소개하며, '검색'과 '연동'이 합쳐진 최종 아키텍처를 보여줍니다.
5.  **결론: 이 책이 약속하는 미래**
    *   독자가 직접 구축하게 될 최종 결과물의 시나리오(연차 확인 + 규정 안내)를 보여주며 동기를 부여합니다.

---

## 3. 상세 기술 레퍼런스 (Technical Reference)

*   **RAG (Retrieval-Augmented Generation)**
    *   구성 요소: 검색기(Retriever) + 생성기(Generator).
    *   핵심 가치: 정보의 최신성 유지, 출처 제시, 환각(Hallucination) 방지.
*   **MCP (Model Context Protocol)**
    *   정의: Anthropic에서 제안한 LLM과 외부 시스템 간의 표준 연결 규격.
    *   장점: 한 번 구축하면 다양한 모델(Claude, DeepSeek 등)에서 재사용 가능.
*   **DeepSeek-R1**
    *   특징: 사고의 사슬(Chain of Thought)을 시각적으로 보여주는 추론 특화형 모델.
    *   역할: 검색된 복잡한 규정 조각들 사이에서 논리적 결론을 도출하는 '뇌' 역할.

---

## 4. 실전 비즈니스 사례 (Use Case Selection)

작가님이 책에서 예시로 쓰기 좋은 시나리오입니다.
*   **인사(HR) 비서**: "신입사원 온보딩 매뉴얼(문서)"과 "직원 명부 DB(정형 데이터)"를 결합하여 답변.
    *   *질문*: "오늘 새로 온 박 사원한테 어떤 장비 지급해야 하고, 지금 재고 있어?"
    *   *작동*: RAG로 지급 규정 확인 + MCP로 재고 DB 조회 후 통합 답변.

---

## 5. 자주 묻는 질문 및 오류 (FAQ & Pitfalls)

*   **Q: 파인튜닝은 아예 안 써도 되나요?**
    *   **A**: 비싼 비용과 데이터 휘발성 때문에 RAG를 먼저 구축하는 것이 정석입니다. 파인튜닝은 나중에 우리 회사만의 '말투'나 '특수 전문 용어'를 학습시킬 때 추가하는 고도화 단계임을 설명해 주세요.
*   **Q: 로컬에서 돌리면 너무 느리지 않을까요?**
    *   **A**: DeepSeek-R1 8B 같은 경량 모델과 Ollama의 최적화를 통해 일반적인 비즈니스 랩탑(RAM 16GB)에서도 실무 가능한 속도가 나옴을 명시하여 독자의 진입 장벽을 낮춰줍니다.

---

## 6. 시각화 아이디어 (Visualization Ideas)

1.  **오픈북 테스트 비유 일러스트**: 책장에 꽂힌 수많은 사내 규정집(VectorDB)에서 필요한 권수를 꺼내(Retriever) 시험지(Response)를 작성하는 AI의 모습.
2.  **통합 아키텍처 레이어**: 
    *   [사용자 UI] -> [LLM 에이전트] -> [분기: RAG(문서) / MCP(계산/조회)] -> [최종 결과].
3.  **데이터 보안 도표**: 클라우드 AI(데이터가 밖으로 나감) vs 로컬 RAG(데이터가 사내 서버 내에 머묾)의 물리적 차이.

---
